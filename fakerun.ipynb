{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys \n",
    "import csv\n",
    "\n",
    "\n",
    "sys.path.append('..')\n",
    "from helpers import *\n",
    "from costs import *\n",
    "from implementationsoreo import *\n",
    "from data_processing import *\n",
    "from cross_validation import cross_validation_with_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data('dataset_to_release', sub_sample=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6562, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loufourneaux/Desktop/EPFL/MA1/ML/project-1-ML/data_processing.py:75: RuntimeWarning: All-NaN slice encountered\n",
      "  \n",
      "/Users/loufourneaux/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1119: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6562, 256)\n",
      "(6562, 160)\n",
      "(6562, 160)\n",
      "(6562, 160)\n",
      "(6562, 82)\n",
      "(6562, 82)\n",
      "(6562, 7)\n"
     ]
    }
   ],
   "source": [
    "new_data=clean_all(x_train[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5918 5194 3135 ... 3980  235 5157]\n"
     ]
    }
   ],
   "source": [
    "#SPLIT DATA\n",
    "x_tr, x_te, y_tr, y_te = split_data(new_data, y_train, 0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#INITIALIZE VARIABLES\n",
    "initial_w=np.ones([new_data.shape[1],1])\n",
    "max_iter= 50\n",
    "gamma = 0.1\n",
    "lambda_= 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=3.313798275887046\n",
      "GD iter. 1/49: loss=2.7840517616805527\n",
      "GD iter. 2/49: loss=2.3545503086229305\n",
      "GD iter. 3/49: loss=2.006231812776654\n",
      "GD iter. 4/49: loss=1.7236761468147732\n",
      "GD iter. 5/49: loss=1.494406066134178\n",
      "GD iter. 6/49: loss=1.3083229336727284\n",
      "GD iter. 7/49: loss=1.1572511438333466\n",
      "GD iter. 8/49: loss=1.0345702094541636\n",
      "GD iter. 9/49: loss=0.9349175654439877\n",
      "GD iter. 10/49: loss=0.853948433693544\n",
      "GD iter. 11/49: loss=0.7881417428499976\n",
      "GD iter. 12/49: loss=0.7346432293113958\n",
      "GD iter. 13/49: loss=0.6911385634043893\n",
      "GD iter. 14/49: loss=0.6557507283318461\n",
      "GD iter. 15/49: loss=0.626956994352132\n",
      "GD iter. 16/49: loss=0.6035217292156226\n",
      "GD iter. 17/49: loss=0.5844420102958587\n",
      "GD iter. 18/49: loss=0.5689035880191996\n",
      "GD iter. 19/49: loss=0.5562452213923786\n",
      "GD iter. 20/49: loss=0.5459297865991499\n",
      "GD iter. 21/49: loss=0.5375208664489851\n",
      "GD iter. 22/49: loss=0.5306637761332678\n",
      "GD iter. 23/49: loss=0.5250701807289219\n",
      "GD iter. 24/49: loss=0.5205056214100847\n",
      "GD iter. 25/49: loss=0.5167793978170665\n",
      "GD iter. 26/49: loss=0.5137363594775132\n",
      "GD iter. 27/49: loss=0.5112502444058062\n",
      "GD iter. 28/49: loss=0.509218271915973\n",
      "GD iter. 29/49: loss=0.5075567524109696\n",
      "GD iter. 30/49: loss=0.5061975219898452\n",
      "GD iter. 31/49: loss=0.5050850461885598\n",
      "GD iter. 32/49: loss=0.5041740666894713\n",
      "GD iter. 33/49: loss=0.5034276887314728\n",
      "GD iter. 34/49: loss=0.5028158263026629\n",
      "GD iter. 35/49: loss=0.5023139378698136\n",
      "GD iter. 36/49: loss=0.5019019980955141\n",
      "GD iter. 37/49: loss=0.5015636612824586\n",
      "GD iter. 38/49: loss=0.5012855806237391\n",
      "GD iter. 39/49: loss=0.5010568540988684\n",
      "GD iter. 40/49: loss=0.5008685733380691\n",
      "GD iter. 41/49: loss=0.500713456224525\n",
      "GD iter. 42/49: loss=0.5005855476125123\n",
      "GD iter. 43/49: loss=0.5004799754673345\n",
      "GD iter. 44/49: loss=0.5003927521099262\n",
      "GD iter. 45/49: loss=0.5003206121786734\n",
      "GD iter. 46/49: loss=0.5002608804881701\n",
      "GD iter. 47/49: loss=0.500211364237768\n",
      "GD iter. 48/49: loss=0.5001702650569305\n",
      "GD iter. 49/49: loss=0.500136107215157\n",
      "score= 0.1686544744379495\n"
     ]
    }
   ],
   "source": [
    "#GRADIENT DESCENT\n",
    "w, loss=mean_squared_error_gd(y_tr, x_tr, initial_w, max_iter,gamma)\n",
    "y_pred=np.dot(x_te,w)\n",
    "score = compute_f1_score(y_te,y_pred)\n",
    "print(\"score=\",score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/49: loss=3.7858231876862076\n",
      "SGD iter. 1/49: loss=3.6989925139945865\n",
      "SGD iter. 2/49: loss=3.591087417535257\n",
      "SGD iter. 3/49: loss=3.1037951627432867\n",
      "SGD iter. 4/49: loss=3.133730703225953\n",
      "SGD iter. 5/49: loss=2.696930505752461\n",
      "SGD iter. 6/49: loss=2.4375409797500316\n",
      "SGD iter. 7/49: loss=2.4503449624508824\n",
      "SGD iter. 8/49: loss=2.206153842867186\n",
      "SGD iter. 9/49: loss=2.11622052381202\n",
      "SGD iter. 10/49: loss=2.133207572172265\n",
      "SGD iter. 11/49: loss=1.900681004451731\n",
      "SGD iter. 12/49: loss=1.617157468756644\n",
      "SGD iter. 13/49: loss=1.4647283234438582\n",
      "SGD iter. 14/49: loss=1.2256288968120823\n",
      "SGD iter. 15/49: loss=1.2344957231489657\n",
      "SGD iter. 16/49: loss=1.267084200506681\n",
      "SGD iter. 17/49: loss=1.0606446678765087\n",
      "SGD iter. 18/49: loss=1.0631577012392825\n",
      "SGD iter. 19/49: loss=1.076233860169259\n",
      "SGD iter. 20/49: loss=0.9857010917775647\n",
      "SGD iter. 21/49: loss=1.0050827793947856\n",
      "SGD iter. 22/49: loss=0.9488396230124586\n",
      "SGD iter. 23/49: loss=0.895230676257322\n",
      "SGD iter. 24/49: loss=0.9256284263785107\n",
      "SGD iter. 25/49: loss=0.9286603430228872\n",
      "SGD iter. 26/49: loss=0.873444720285965\n",
      "SGD iter. 27/49: loss=0.9066767792358791\n",
      "SGD iter. 28/49: loss=0.7015312305985614\n",
      "SGD iter. 29/49: loss=0.7290803619520085\n",
      "SGD iter. 30/49: loss=0.7784872954734601\n",
      "SGD iter. 31/49: loss=0.8486564486719882\n",
      "SGD iter. 32/49: loss=0.8793827823861212\n",
      "SGD iter. 33/49: loss=0.9097139753281783\n",
      "SGD iter. 34/49: loss=0.9432928532401604\n",
      "SGD iter. 35/49: loss=0.9347792187806752\n",
      "SGD iter. 36/49: loss=0.7913400143016792\n",
      "SGD iter. 37/49: loss=0.7548640851502398\n",
      "SGD iter. 38/49: loss=0.7555641663116288\n",
      "SGD iter. 39/49: loss=0.7868963024432731\n",
      "SGD iter. 40/49: loss=0.7962682420696585\n",
      "SGD iter. 41/49: loss=0.6443355673736654\n",
      "SGD iter. 42/49: loss=0.8142395478615664\n",
      "SGD iter. 43/49: loss=0.8170503333085231\n",
      "SGD iter. 44/49: loss=0.9372590413449662\n",
      "SGD iter. 45/49: loss=0.7283080923029004\n",
      "SGD iter. 46/49: loss=0.6962038108290826\n",
      "SGD iter. 47/49: loss=0.7343313986529053\n",
      "SGD iter. 48/49: loss=0.7567633405939524\n",
      "SGD iter. 49/49: loss=0.8347775037641325\n",
      "score= 0.16813373251549038\n"
     ]
    }
   ],
   "source": [
    "#STOCHASTIC GD\n",
    "w1, loss1=mean_squared_error_sgd(y_tr, x_tr, initial_w, max_iter, gamma)\n",
    "y_pred1=np.dot(x_te, w1)\n",
    "score1= compute_f1_score(y_te, y_pred1)\n",
    "print(\"score=\",score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score= 0.1900121802679659\n"
     ]
    }
   ],
   "source": [
    "#LEAST SQUARES\n",
    "w2, loss2=least_squares(y_tr, x_tr)\n",
    "y_pred2=np.dot(x_te, w2)\n",
    "score2= compute_f1_score(y_te, y_pred2)\n",
    "print(\"score=\",score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score= 0.18491484184914841\n"
     ]
    }
   ],
   "source": [
    "#RIDGE REGRESSION\n",
    "w3, loss3=ridge_regression(y_tr, x_tr, lambda_)\n",
    "y_pred3=np.dot(x_te, w3)\n",
    "score3 = compute_f1_score(y_te,y_pred3)\n",
    "print(\"score=\",score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=1.1852191065815472\n",
      "GD iter. 1/49: loss=1.1112483088656222\n",
      "GD iter. 2/49: loss=1.047187274599875\n",
      "GD iter. 3/49: loss=0.9919434274538356\n",
      "GD iter. 4/49: loss=0.944509551637713\n",
      "GD iter. 5/49: loss=0.9039592830831811\n",
      "GD iter. 6/49: loss=0.8694438119485683\n",
      "GD iter. 7/49: loss=0.8401893492237879\n",
      "GD iter. 8/49: loss=0.8154949032984007\n",
      "GD iter. 9/49: loss=0.7947299764331425\n",
      "GD iter. 10/49: loss=0.7773318946392481\n",
      "GD iter. 11/49: loss=0.7628026053961817\n",
      "GD iter. 12/49: loss=0.7507048959453144\n",
      "GD iter. 13/49: loss=0.7406580844606704\n",
      "GD iter. 14/49: loss=0.7323333072542365\n",
      "GD iter. 15/49: loss=0.7254485642249724\n",
      "GD iter. 16/49: loss=0.7197636947591509\n",
      "GD iter. 17/49: loss=0.7150754437562232\n",
      "GD iter. 18/49: loss=0.7112127503891923\n",
      "GD iter. 19/49: loss=0.708032358227743\n",
      "GD iter. 20/49: loss=0.705414810550893\n",
      "GD iter. 21/49: loss=0.7032608631988201\n",
      "GD iter. 22/49: loss=0.7014883214435959\n",
      "GD iter. 23/49: loss=0.7000292878878981\n",
      "GD iter. 24/49: loss=0.6988277950891928\n",
      "GD iter. 25/49: loss=0.6978377886171191\n",
      "GD iter. 26/49: loss=0.6970214224876128\n",
      "GD iter. 27/49: loss=0.6963476282641762\n",
      "GD iter. 28/49: loss=0.6957909205776389\n",
      "GD iter. 29/49: loss=0.6953304045783283\n",
      "GD iter. 30/49: loss=0.6949489542811683\n",
      "GD iter. 31/49: loss=0.6946325344564096\n",
      "GD iter. 32/49: loss=0.6943696423652492\n",
      "GD iter. 33/49: loss=0.694150849062445\n",
      "GD iter. 34/49: loss=0.6939684230922503\n",
      "GD iter. 35/49: loss=0.6938160221492682\n",
      "GD iter. 36/49: loss=0.6936884406602276\n",
      "GD iter. 37/49: loss=0.6935814032838841\n",
      "GD iter. 38/49: loss=0.6934913960555905\n",
      "GD iter. 39/49: loss=0.6934155283556729\n",
      "GD iter. 40/49: loss=0.6933514200924411\n",
      "GD iter. 41/49: loss=0.6932971094970121\n",
      "GD iter. 42/49: loss=0.6932509777586009\n",
      "GD iter. 43/49: loss=0.6932116874141699\n",
      "GD iter. 44/49: loss=0.6931781319696375\n",
      "GD iter. 45/49: loss=0.6931493946916313\n",
      "GD iter. 46/49: loss=0.693124714886972\n",
      "GD iter. 47/49: loss=0.693103460296559\n",
      "GD iter. 48/49: loss=0.6930851044828842\n",
      "GD iter. 49/49: loss=0.6930692082968678\n",
      "score= 0.1686544744379495\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#LOG REGRESSION\n",
    "w4, loss4=logistic_regression(y_tr, x_tr, initial_w, max_iter,gamma)\n",
    "y_pred4=np.dot(x_te,w4)\n",
    "score4 = compute_f1_score(y_te,y_pred4)\n",
    "print(\"score=\", score4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/9: loss=4.515063381108995\n",
      "GD iter. 1/9: loss=1.0376966605362987\n",
      "GD iter. 2/9: loss=0.7235724189844503\n",
      "GD iter. 3/9: loss=0.6960263971657915\n",
      "GD iter. 4/9: loss=0.6933523891428259\n",
      "GD iter. 5/9: loss=0.6931696216944007\n",
      "GD iter. 6/9: loss=0.6931357188407876\n",
      "GD iter. 7/9: loss=0.6931378283068328\n",
      "GD iter. 8/9: loss=0.6931364764328496\n",
      "GD iter. 9/9: loss=0.6931368131584328\n",
      "score= 0.16981041169810412\n"
     ]
    }
   ],
   "source": [
    "#REG LOG REGRESSION\n",
    "w5, loss5=reg_logistic_regression(y_tr, x_tr,lambda_, initial_w, max_iter,gamma)\n",
    "y_pred5=np.dot(x_te,w5)\n",
    "score5 = compute_f1_score(y_te,y_pred5)\n",
    "print(\"score=\",score5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (623948613.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [28]\u001b[0;36m\u001b[0m\n\u001b[0;31m    param_GD, loss_GD= cross_validation_with_degree(y_tr, x_tr, hyperparametersGD, \"mean_squared_error_gd)\u001b[0m\n\u001b[0m                                                                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "#cross-valdiation\n",
    "hyperparametersGD = [\n",
    "    {\"method\": \"mean_squared_error_gd\", \"initial_w\": np.ones(clean_xtrain.shape[1],), \"max_iters\": 5, \"gamma\": 0.1}#, \"degree\": 1},\n",
    "    # Add more hyperparameters for MSE with GD as needed\n",
    "]\n",
    "#GD\n",
    "param_GD, loss_GD= cross_validation_with_degree(y_tr, x_tr, 5 , hyperparametersGD, \"mean_squared_error_gd\")\n",
    "w, loss= mean_squared_error_gd(y_tr, x_tr, hyperparametersGD)\n",
    "y_pred=np.dot(x_te,w)\n",
    "score = compute_f1_score(y_te, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e307f64f8169f2306a2b86f942e25c607f260ae29e965409017f9df1666892e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
