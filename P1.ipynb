{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def load_csv_data(data_path, sub_sample=False):\n",
    "    \"\"\"\n",
    "    This function loads the data and returns the respectinve numpy arrays.\n",
    "    Remember to put the 3 files in the same folder and to not change the names of the files.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): datafolder path\n",
    "        sub_sample (bool, optional): If True the data will be subsempled. Default to False.\n",
    "\n",
    "    Returns:\n",
    "        x_train (np.array): training data\n",
    "        x_test (np.array): test data\n",
    "        y_train (np.array): labels for training data in format (-1,1)\n",
    "        train_ids (np.array): ids of training data\n",
    "        test_ids (np.array): ids of test data\n",
    "    \"\"\"\n",
    "    y_train = np.genfromtxt(\n",
    "        os.path.join(data_path, \"y_train.csv\"),\n",
    "        delimiter=\",\",\n",
    "        skip_header=1,\n",
    "        dtype=int,\n",
    "        usecols=1,\n",
    "    )\n",
    "    x_train = np.genfromtxt(\n",
    "        os.path.join(data_path, \"x_train.csv\"), delimiter=\",\", skip_header=1\n",
    "    )\n",
    "    x_test = np.genfromtxt(\n",
    "        os.path.join(data_path, \"x_test.csv\"), delimiter=\",\", skip_header=1\n",
    "    )\n",
    "\n",
    "    train_ids = x_train[:, 0].astype(dtype=int)\n",
    "    test_ids = x_test[:, 0].astype(dtype=int)\n",
    "    x_train = x_train[:, 1:]\n",
    "    x_test = x_test[:, 1:]\n",
    "\n",
    "    # sub-sample\n",
    "    if sub_sample:\n",
    "        y_train = y_train[::50]\n",
    "        x_train = x_train[::50]\n",
    "        train_ids = train_ids[::50]\n",
    "\n",
    "    return x_train, x_test, y_train, train_ids, test_ids\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T13:33:55.837210Z",
     "start_time": "2023-10-23T13:33:54.626559100Z"
    }
   },
   "id": "328eb23b25b4b9ed"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-23T13:39:16.598456700Z",
     "start_time": "2023-10-23T13:34:15.533846100Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,train_ids, test_ids = load_csv_data(r\"C:\\Users\\adrie\\OneDrive\\Documents\\EPFL\\ML\\Project 1\\dataset\\dataset\\dataset_to_release\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.30000000e+01 1.10000000e+01 1.11620150e+07 1.10000000e+01\n",
      " 1.60000000e+01 2.01500000e+03 1.10000000e+03 2.01501563e+09\n",
      " 2.01501563e+09            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan 1.00000000e+00 1.00000000e+00\n",
      " 2.00000000e+00 1.00000000e+00            nan 1.00000000e+00\n",
      " 1.00000000e+00 2.00000000e+00 2.00000000e+00 1.00000000e+00\n",
      " 5.00000000e+00 8.80000000e+01 1.00000000e+00 1.00000000e+00\n",
      " 2.00000000e+00 1.00000000e+00 3.00000000e+00            nan\n",
      " 1.00000000e+00 1.00000000e+00 2.00000000e+00 2.00000000e+00\n",
      " 2.00000000e+00            nan 2.00000000e+00 2.00000000e+00\n",
      " 2.00000000e+00 2.00000000e+00 1.00000000e+00 2.00000000e+00\n",
      " 3.00000000e+00            nan 2.00000000e+00 1.00000000e+00\n",
      " 5.00000000e+00 1.00000000e+00            nan            nan\n",
      "            nan 2.00000000e+00 1.00000000e+00 8.80000000e+01\n",
      " 8.00000000e+00 1.00000000e+00 1.10000000e+02 5.01000000e+02\n",
      "            nan 1.00000000e+00 2.00000000e+00 2.00000000e+00\n",
      " 2.00000000e+00 2.00000000e+00 2.00000000e+00 2.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00            nan\n",
      " 3.00000000e+00 8.88000000e+02            nan            nan\n",
      "            nan 5.55000000e+02 2.05000000e+02 3.04000000e+02\n",
      " 3.03000000e+02 3.08000000e+02 2.05000000e+02 1.00000000e+00\n",
      " 6.40000000e+01 1.02000000e+02 3.00000000e+01 9.80000000e+01\n",
      " 2.20000000e+02 3.00000000e+01 1.05000000e+02            nan\n",
      "            nan            nan            nan 1.00000000e+00\n",
      " 1.00000000e+00 1.02015000e+05 8.00000000e+00 2.00000000e+00\n",
      " 2.00000000e+00            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan 1.00000000e+00 3.00000000e+00\n",
      " 1.00000000e+00 5.00000000e+00 2.00000000e+00            nan\n",
      " 1.00000000e+00            nan            nan 1.00000000e+00\n",
      " 4.00000000e+00 1.00000000e+00 2.00000000e+00 4.00000000e+00\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 2.00000000e+01 1.00000000e+00            nan 5.32049000e+05\n",
      " 1.20931680e+02 1.00000000e+00 1.20931680e+02            nan\n",
      "            nan            nan            nan 2.00000000e+00\n",
      " 2.33947890e-01 2.64741181e+02 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 3.00000000e+00 2.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 2.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 8.00000000e+00 1.00000000e+00\n",
      " 5.70000000e+01 5.00000000e+00 6.10000000e+01 1.55000000e+00\n",
      " 4.99000000e+01 2.07800000e+01 2.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 3.00000000e+00 5.00000000e+00 1.00000000e+00\n",
      " 2.00000000e+00 2.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 7.10000000e-01\n",
      " 1.30000000e-01 1.00000000e-01 2.70000000e-01 7.10000000e-01\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 7.10000000e-01 1.21000000e+00 2.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 3.50000000e+00 4.50000000e+00 2.69100000e+01\n",
      " 4.61000000e+00 1.00000000e+00 1.00000000e+00 3.00000000e+01\n",
      " 3.00000000e+01 2.00000000e+00 4.66700000e+00 6.00000000e+01\n",
      " 1.40000000e+02 5.00000000e+00 0.00000000e+00 6.00000000e+01\n",
      " 1.40000000e+02 2.00000000e+02 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 2.00000000e+00 2.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 3.00000000e+00 3.00000000e+00 4.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00            nan            nan\n",
      " 2.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T12:46:02.020807600Z",
     "start_time": "2023-10-22T12:46:01.974545700Z"
    }
   },
   "id": "ebe02fe3853df7a2"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0      1      2 ... 328132 328133 328134]\n"
     ]
    }
   ],
   "source": [
    "print(train_ids)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T12:46:19.739688800Z",
     "start_time": "2023-10-22T12:46:19.480209800Z"
    }
   },
   "id": "5a9c2a898f30110c"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.any(x_train == 888))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T08:40:48.118208400Z",
     "start_time": "2023-10-22T08:40:46.791716800Z"
    }
   },
   "id": "e370db97e716c431"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def cleaning_answers(data):\n",
    "    datas_cleaned = data.copy()\n",
    "    \n",
    "    for i in range(datas_cleaned.shape[1]):\n",
    "        unique_values = np.unique(datas_cleaned[:,i])\n",
    "        nbr_unique_values = len(unique_values)\n",
    "        max_value = np.nanmax(datas_cleaned[:,i])\n",
    "        median = np.nanmedian(datas_cleaned[:,i])\n",
    "        conditions = []\n",
    "        replacement = []\n",
    "        if nbr_unique_values <= 5 and max_value <= 9:\n",
    "            if 7 in unique_values:\n",
    "                conditions.append(datas_cleaned[:,i]==7)\n",
    "                replacement.append(2)\n",
    "            if 8 in unique_values:\n",
    "                conditions.append(datas_cleaned[:,i]==8)\n",
    "                replacement.append(2)\n",
    "            if 9 in unique_values:\n",
    "                conditions.append(datas_cleaned[:,i]==9)\n",
    "                replacement.append(2)\n",
    "                \n",
    "        elif nbr_unique_values >5 and max_value <= 9:\n",
    "            if 7 in unique_values:\n",
    "                conditions.append(datas_cleaned[:,i]==7)\n",
    "                replacement.append(2)\n",
    "            if 8 in unique_values:\n",
    "                conditions.append(datas_cleaned[:,i]==8)\n",
    "                replacement.append(0)\n",
    "            if 9 in unique_values:\n",
    "                conditions.append(datas_cleaned[:,i]==9)\n",
    "                replacement.append(2)\n",
    "            \n",
    "        elif (max_value <= 99 and max_value > 9):\n",
    "            if 77 in unique_values:\n",
    "                conditions.append(datas_cleaned[:,i]==77)\n",
    "                replacement.append(median)\n",
    "            if 88 in unique_values:\n",
    "                conditions.append(datas_cleaned[:,i]==88)\n",
    "                replacement.append(0)\n",
    "            if 99 in unique_values:\n",
    "                conditions.append(datas_cleaned[:,i]==99)\n",
    "                replacement.append(median)\n",
    "            \n",
    "        elif (max_value <= 999 and max_value > 99 ):\n",
    "            if 777 in unique_values:\n",
    "                conditions.append(datas_cleaned[:,i]==777)\n",
    "                replacement.append(median)\n",
    "            if 888 in unique_values:\n",
    "                conditions.append(datas_cleaned[:,i]==888)\n",
    "                replacement.append(0)\n",
    "            if 999 in unique_values:\n",
    "                conditions.append(datas_cleaned[:,i]==999)\n",
    "                replacement.append(median)\n",
    "            \n",
    "        elif max_value > 999 and max_value <= 9999:\n",
    "            if 7777 in unique_values:\n",
    "                conditions.append(datas_cleaned[:,i]==7777)\n",
    "                replacement.append(median)\n",
    "            if 8888 in unique_values:\n",
    "                conditions.append(datas_cleaned[:,i]==8888)\n",
    "                replacement.append(median)\n",
    "            if 9999 in unique_values:\n",
    "                conditions.append(datas_cleaned[:,i]==9999)\n",
    "                replacement.append(median)\n",
    "                \n",
    "        elif max_value > 9999 and max_value <= 999999:\n",
    "            if 777777 in unique_values:\n",
    "                conditions.append(datas_cleaned[:,i]==777777)\n",
    "                replacement.append(median)\n",
    "            if 888888 in unique_values:\n",
    "                conditions.append(datas_cleaned[:,i]==888888)\n",
    "                replacement.append(median)\n",
    "            if 999999 in unique_values:\n",
    "                conditions.append(datas_cleaned[:,i]==999999)\n",
    "                replacement.append(median)\n",
    "\n",
    "        for condition, replacement in zip(conditions, replacement):\n",
    "            datas_cleaned[condition, i] = replacement\n",
    "    return datas_cleaned"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T13:39:16.664177100Z",
     "start_time": "2023-10-23T13:39:16.544025500Z"
    }
   },
   "id": "b7ad1235c2bf697b"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données d'origine :\n",
      "[[      1       2       3       4]\n",
      " [      2       8       9      10]\n",
      " [      7      88      99     100]\n",
      " [      9     888     999    1000]\n",
      " [      1    8888    9999   10000]\n",
      " [      2  888888  999999 1000000]]\n",
      "\n",
      "Données nettoyées :\n",
      "[[      1       2       3       4]\n",
      " [      2       8       9      10]\n",
      " [      2       0     549     100]\n",
      " [      2     888     999    1000]\n",
      " [      1    8888    9999   10000]\n",
      " [      2  888888  999999 1000000]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Définir un exemple d'ensemble de données\n",
    "data = np.array([[1, 2, 3, 4],\n",
    "                 [2, 8, 9, 10],\n",
    "                 [7, 88, 99, 100],\n",
    "                 [9, 888, 999, 1000],\n",
    "                 [1, 8888, 9999, 10000],\n",
    "                 [2, 888888, 999999, 1000000]])\n",
    "\n",
    "# Appeler la fonction de nettoyage\n",
    "cleaned_data = cleaning_answers(data)\n",
    "\n",
    "# Afficher le résultat\n",
    "print(\"Données d'origine :\")\n",
    "print(data)\n",
    "print(\"\\nDonnées nettoyées :\")\n",
    "print(cleaned_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T09:42:40.131110600Z",
     "start_time": "2023-10-22T09:42:40.109695500Z"
    }
   },
   "id": "1eba6d46c33d4d0e"
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition 2\n",
      "condition 2\n",
      "condition 2\n",
      "condition 2\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 2\n",
      "condition 2\n",
      "condition 2\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 2\n",
      "condition 1\n",
      "condition 2\n",
      "condition 2\n",
      "condition 2\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 2\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 2\n",
      "condition 2\n",
      "condition 1\n",
      "condition 4\n",
      "condition 4\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 2\n",
      "condition 1\n",
      "condition 3\n",
      "condition 2\n",
      "condition 2\n",
      "condition 2\n",
      "condition 3\n",
      "condition 3\n",
      "condition 3\n",
      "condition 3\n",
      "condition 3\n",
      "condition 3\n",
      "condition 1\n",
      "condition 2\n",
      "condition 3\n",
      "condition 3\n",
      "condition 2\n",
      "condition 3\n",
      "condition 3\n",
      "condition 3\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 2\n",
      "condition 1\n",
      "condition 1\n",
      "condition 5\n",
      "condition 2\n",
      "condition 1\n",
      "condition 1\n",
      "condition 5\n",
      "condition 2\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 3\n",
      "condition 3\n",
      "condition 2\n",
      "condition 2\n",
      "condition 2\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 2\n",
      "condition 1\n",
      "condition 1\n",
      "condition 2\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 2\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 3\n",
      "condition 1\n",
      "condition 2\n",
      "condition 1\n",
      "condition 2\n",
      "condition 2\n",
      "condition 2\n",
      "condition 3\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 2\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 2\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 2\n",
      "condition 1\n",
      "condition 2\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 2\n",
      "condition 2\n",
      "condition 2\n",
      "condition 2\n",
      "condition 2\n",
      "condition 2\n",
      "condition 2\n",
      "condition 2\n",
      "condition 1\n",
      "condition 1\n",
      "condition 2\n",
      "condition 1\n",
      "condition 1\n",
      "condition 5\n",
      "condition 4\n",
      "condition 1\n",
      "condition 4\n",
      "condition 1\n",
      "condition 2\n",
      "condition 2\n",
      "condition 5\n",
      "condition 1\n",
      "condition 1\n",
      "condition 5\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 2\n",
      "condition 2\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 2\n",
      "condition 1\n",
      "condition 2\n",
      "condition 1\n",
      "condition 2\n",
      "condition 1\n",
      "condition 3\n",
      "condition 2\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 3\n",
      "condition 1\n",
      "condition 5\n",
      "condition 1\n",
      "condition 2\n",
      "condition 2\n",
      "condition 2\n",
      "condition 2\n",
      "condition 2\n",
      "condition 2\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 3\n",
      "condition 3\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 2\n",
      "condition 2\n",
      "condition 3\n",
      "condition 3\n",
      "condition 1\n",
      "condition 1\n",
      "condition 3\n",
      "condition 3\n",
      "condition 2\n",
      "condition 2\n",
      "condition 5\n",
      "condition 5\n",
      "condition 2\n",
      "condition 1\n",
      "condition 5\n",
      "condition 5\n",
      "condition 5\n",
      "condition 5\n",
      "condition 5\n",
      "condition 5\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n",
      "condition 1\n"
     ]
    }
   ],
   "source": [
    "x_train_clean01 = cleaning_answers(x_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T14:51:03.751700600Z",
     "start_time": "2023-10-22T14:50:30.009984100Z"
    }
   },
   "id": "248e5e7cae132df"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def remove_useless_col(data):\n",
    "    col_to_remove = [1,2,3,4,5, 9, 10,11,12,13,18,19,21,22,24,52, 53, 54,60, 98,104,105,119,120,121,122,123,124,125,126,130,131,132,133,166,179,181,211, 212, 216, 217, 219, 220, 221, 222, 226, 227, 228, 229, 235, 236, 237, 239, 240, 241, 244, 245, 246, 256, 286, 310, 311, 316, 317, 320]\n",
    "    return np.delete(data, col_to_remove, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T13:39:16.670181100Z",
     "start_time": "2023-10-23T13:39:16.591987200Z"
    }
   },
   "id": "c1d5ac91fe076abd"
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "x_train_clean_02 = remove_useless_col(x_train_clean01)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T12:39:42.246107500Z",
     "start_time": "2023-10-23T12:39:31.337562200Z"
    }
   },
   "id": "cd7bcf8729950027"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def remove_nan_col(x, nan_percentage = 0.8) :\n",
    "\n",
    "    #Remove columns in which there are too much NaN values (<80%)\n",
    "    to_delete = []\n",
    "    for i in range(x.shape[1] - 1, 1, -1):\n",
    "        num_NaN = np.count_nonzero(np.isnan(x[:,i]))\n",
    "        p_NaN = num_NaN / x.shape[0]\n",
    "        if p_NaN > nan_percentage:\n",
    "            to_delete.append(i)\n",
    "\n",
    "    x = x[:, [i for i in range(x.shape[1]) if i not in to_delete]]\n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T13:39:16.671190Z",
     "start_time": "2023-10-23T13:39:16.592984900Z"
    }
   },
   "id": "d65c21b36eff3785"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "x_train_clean1 = remove_nan_col(x_train_clean_02)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T16:02:14.550061700Z",
     "start_time": "2023-10-21T16:01:54.231638700Z"
    }
   },
   "id": "9d727aa7280970eb"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 204)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_clean1.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T16:02:14.653690Z",
     "start_time": "2023-10-21T16:02:14.587082200Z"
    }
   },
   "id": "a6ffc5dfdd1fef49"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    clean_datas = data.copy()\n",
    "\n",
    "    for i in range(data.shape[1]):\n",
    "        col = clean_datas[:, i]\n",
    "        is_nan = np.isnan(col)\n",
    "\n",
    "        if is_nan.any():\n",
    "            valid_values = col[~is_nan]\n",
    "            if valid_values.size > 0:\n",
    "                median = np.median(valid_values)\n",
    "                col[is_nan] = median\n",
    "\n",
    "    return clean_datas"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T13:39:16.672187900Z",
     "start_time": "2023-10-23T13:39:16.592984900Z"
    }
   },
   "id": "72dd12293f6973a5"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "x_train_clean2 = clean_data(x_train_clean1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T16:05:51.680539600Z",
     "start_time": "2023-10-21T16:05:38.086433200Z"
    }
   },
   "id": "32b35af6dce0c4b8"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(x_train_clean2).any())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T16:06:49.337224100Z",
     "start_time": "2023-10-21T16:06:49.161873500Z"
    }
   },
   "id": "1eac8e31faa24a4e"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def remove_outliers(data):\n",
    "\n",
    "    filtered_data = data.copy()\n",
    "    for i in range(filtered_data.shape[1]):\n",
    "        col_data = filtered_data[:,i]\n",
    "        q1 = np.percentile(col_data,25)\n",
    "        q3 = np.percentile(col_data,75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5*iqr\n",
    "        upper_bound = q3 + 1.5*iqr\n",
    "\n",
    "        col_data[(col_data<lower_bound)|(col_data>upper_bound)] = np.median(col_data)\n",
    "        filtered_data[:,i]= col_data\n",
    "    return filtered_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T13:39:16.672187900Z",
     "start_time": "2023-10-23T13:39:16.629483100Z"
    }
   },
   "id": "a004475d6f36a2a7"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x_train_clean3 = remove_outliers(x_train_clean2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T16:23:20.491990500Z",
     "start_time": "2023-10-21T16:22:57.693991900Z"
    }
   },
   "id": "5a915708b6d9023c"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[  1   2   3]\n",
      " [  4   5   6]\n",
      " [100 110 120]\n",
      " [  7   8   9]]\n",
      "[28.   31.25 34.5 ]\n",
      "[41.62331078 45.51579396 49.40900728]\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [5 6 7]\n",
      " [7 8 9]]\n",
      "[4.25 5.25 6.25]\n",
      "[2.16506351 2.16506351 2.16506351]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[1, 2, 3],\n",
    "                 [4, 5, 6],\n",
    "                 [100, 110, 120],\n",
    "                 [7, 8, 9]])\n",
    "\n",
    "cleaned_datas = remove_outliers(data)\n",
    "\n",
    "mean_before = np.mean(data, axis=0)\n",
    "std_before = np.std(data, axis=0)\n",
    "mean_after = np.mean(cleaned_datas, axis=0)\n",
    "std_after = np.std(cleaned_datas, axis=0)\n",
    "print(data)\n",
    "print( mean_before)\n",
    "print(std_before)\n",
    "print(cleaned_datas)\n",
    "print( mean_after)\n",
    "print( std_after)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T16:22:46.136887300Z",
     "start_time": "2023-10-21T16:22:45.983633400Z"
    }
   },
   "id": "e06d25f1ecb73743"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def standardize(data):\n",
    "\n",
    "    mean = np.mean(data, axis=0)\n",
    "    std = np.std(data, axis= 0)\n",
    "    for i in range(len(std)):\n",
    "        if std[i] < 1e-10:\n",
    "            std[i] = 1\n",
    "    standardized_data = (data - mean)/std\n",
    "    return standardized_data\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T13:39:16.672187900Z",
     "start_time": "2023-10-23T13:39:16.629483100Z"
    }
   },
   "id": "ac9a41f880ecd579"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "x_train_clean4 = standardize(x_train_clean3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T16:37:00.943206200Z",
     "start_time": "2023-10-21T16:36:48.294746500Z"
    }
   },
   "id": "cb7d3cd57a86067b"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistiques des données avant la standardisation:\n",
      "Moyenne avant : [4. 5. 6.]\n",
      "Écart type avant : [2.44948974 2.44948974 2.44948974]\n",
      "\n",
      "Statistiques des données après la standardisation:\n",
      "Moyenne après : [0. 0. 0.]\n",
      "Écart type après : [1. 1. 1.]\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "Données standardisées :\n",
      "[[-1.22474487 -1.22474487 -1.22474487]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 1.22474487  1.22474487  1.22474487]]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[1, 2, 3],\n",
    "                 [4, 5, 6],\n",
    "                 [7, 8, 9]])\n",
    "\n",
    "# Appelez la fonction de standardisation sur les données d'exemple\n",
    "standardized_data = standardize(data)\n",
    "\n",
    "# Comparez les statistiques des données avant et après\n",
    "mean_before = np.mean(data, axis=0)\n",
    "std_before = np.std(data, axis=0)\n",
    "mean_after = np.mean(standardized_data, axis=0)\n",
    "std_after = np.std(standardized_data, axis=0)\n",
    "print(\"Statistiques des données avant la standardisation:\")\n",
    "print(\"Moyenne avant :\", mean_before)\n",
    "print(\"Écart type avant :\", std_before)\n",
    "\n",
    "print(\"\\nStatistiques des données après la standardisation:\")\n",
    "print(\"Moyenne après :\", mean_after)\n",
    "print(\"Écart type après :\", std_after)\n",
    "\n",
    "# Vérifiez visuellement les données standardisées\n",
    "print(data)\n",
    "print(\"Données standardisées :\")\n",
    "print(standardized_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T16:31:53.433935Z",
     "start_time": "2023-10-21T16:31:53.351392700Z"
    }
   },
   "id": "3a3b5cee07e9c6a6"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def remove_correlated_columns(data, correlation_threshold=0.7):\n",
    "    indices=[]\n",
    "\n",
    "    for i in range(data.shape[1]):\n",
    "        for j in range(i+1,data.shape[1]):\n",
    "            col1 = data[:,i]\n",
    "            col2 = data[:,j]\n",
    "            corr = np.corrcoef(col1, col2)\n",
    "\n",
    "            if (np.abs(corr[0][1]) >= correlation_threshold):\n",
    "                indices.append(j)\n",
    "\n",
    "    uncorrelated_data = np.delete(data,indices,1)\n",
    "    return uncorrelated_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T13:39:16.672187900Z",
     "start_time": "2023-10-23T13:39:16.630482800Z"
    }
   },
   "id": "e36cd3f41fcac38d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train_clean5 = remove_correlated_columns(x_train_clean4)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e70a9058b993e296"
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.    2.    3.    5. ]\n",
      " [  4.    5.    6.  -12. ]\n",
      " [ -7.    8.    9.    3.5]\n",
      " [ 10.   11.   12.   54. ]]\n",
      "[[ 1.  2.]\n",
      " [ 4.  5.]\n",
      " [-7.  8.]\n",
      " [10. 11.]]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[1, 2, 3, 5],\n",
    "                 [4, 5, 6, 12],\n",
    "                 [-7, 8, 9, 3.5 ],\n",
    "                 [10, 11, 12, 54]])\n",
    "\n",
    "datas_cleaned = remove_correlated_columns(data)\n",
    "print(data)\n",
    "print(datas_cleaned)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T14:45:52.911643800Z",
     "start_time": "2023-10-22T14:45:52.810052700Z"
    }
   },
   "id": "ec66e22c189e1d6f"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def clean_all(data):\n",
    "    data_to_compute = remove_useless_col(data)\n",
    "    print(data_to_compute.shape)\n",
    "    data_to_compute = cleaning_answers(data_to_compute)\n",
    "    print(data_to_compute.shape)\n",
    "    data_to_compute = remove_nan_col(data_to_compute)\n",
    "    print(data_to_compute.shape)\n",
    "    data_to_compute = clean_data(data_to_compute)    \n",
    "    print(data_to_compute.shape)\n",
    "    data_to_compute = remove_outliers(data_to_compute)\n",
    "    print(data_to_compute.shape)\n",
    "    data_to_compute = standardize(data_to_compute)\n",
    "    print(data_to_compute.shape)\n",
    "    data_to_compute = remove_correlated_columns(data_to_compute)\n",
    "    print(data_to_compute.shape)\n",
    "    return data_to_compute.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T13:39:16.683178900Z",
     "start_time": "2023-10-23T13:39:16.648616500Z"
    }
   },
   "id": "6f235c7e33718bac"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 256)\n",
      "(328135, 256)\n",
      "(328135, 160)\n",
      "(328135, 160)\n",
      "(328135, 160)\n",
      "(328135, 160)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adrie\\anaconda3\\envs\\ADA\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\adrie\\anaconda3\\envs\\ADA\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 135)\n"
     ]
    }
   ],
   "source": [
    "new_datas = clean_all(x_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T13:43:01.518303400Z",
     "start_time": "2023-10-23T13:39:16.659176800Z"
    }
   },
   "id": "e267f0ebb791f6a7"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135, 1)\n",
      "(328135, 135)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_iters = 500\n",
    "initial_w = np.ones((new_datas.shape[1],1))\n",
    "gamma = 0.1\n",
    "print(initial_w.shape)\n",
    "print(new_datas.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T13:57:07.552891900Z",
     "start_time": "2023-10-23T13:57:07.524322300Z"
    }
   },
   "id": "84a4266f95745067"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Computes the gradient at w.\n",
    "\n",
    "    Args:\n",
    "        y: shape=(N, )\n",
    "        tx: shape=(N,2)\n",
    "        w: shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        An array of shape (2, ) (same shape as w), containing the gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    y = y.reshape(-1,1)\n",
    "\n",
    "    e = y - tx.dot(w)\n",
    "    gradient = (-1/y.shape[0])*np.dot(tx.T,e)\n",
    "    return gradient\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T13:54:13.194299700Z",
     "start_time": "2023-10-23T13:54:13.172746500Z"
    }
   },
   "id": "a230211e4c8096ec"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def compute_mse(y, tx, w):\n",
    "    \"\"\"compute the loss by mse.\n",
    "    Args:\n",
    "        y: numpy array of shape (N,), N is the number of samples.\n",
    "        tx: numpy array of shape (N,D), D is the number of features.\n",
    "        w: weights, numpy array of shape(D,), D is the number of features.\n",
    "\n",
    "    Returns:\n",
    "        mse: scalar corresponding to the mse with factor (1 / 2 n) in front of the sum\n",
    "\n",
    "    >>> compute_mse(np.array([0.1,0.2]), np.array([[2.3, 3.2], [1., 0.1]]), np.array([0.03947092, 0.00319628]))\n",
    "    0.006417022764962313\n",
    "    \"\"\"\n",
    "    y = y.reshape(-1,1)\n",
    "    e = y - tx.dot(w)\n",
    "    mse = e.T.dot(e) / (2 * len(e))\n",
    "    return mse"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T13:53:31.546991500Z",
     "start_time": "2023-10-23T13:53:31.513119400Z"
    }
   },
   "id": "2deddf54359d2a76"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def gradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The Gradient Descent (GD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of GD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of GD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute gradient and loss\n",
    "        grad = compute_gradient(y, tx, w)\n",
    "        loss = compute_mse(y, tx, w)\n",
    "\n",
    "        # update w by gradient\n",
    "        w = w - gamma * grad\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        if n_iter % 20 == 0:\n",
    "            print(\n",
    "                \"GD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}, w3={w3}\".format(\n",
    "                    bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1], w3= w[3]\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return w, losses"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T14:07:54.448094300Z",
     "start_time": "2023-10-23T14:07:54.337727900Z"
    }
   },
   "id": "1681eedf4b2a00c0"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def mean_squared_error_gd(y, tx, initial_w,max_iters, gamma):\n",
    "    #gradient descent\n",
    "    losses, ws = gradient_descent(y, tx, initial_w, max_iters, gamma)\n",
    "\n",
    "    #find the best w\n",
    "    if gamma <= 2 :\n",
    "        loss = losses[-1]\n",
    "        w = ws[-1]\n",
    "    else :\n",
    "        loss = np.min(losses)\n",
    "        w = ws[np.argmin(losses)]\n",
    "\n",
    "    return w, loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T13:45:28.084187100Z",
     "start_time": "2023-10-23T13:45:28.073629600Z"
    }
   },
   "id": "949a931607603d3c"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/499: loss=[[46.85457533]], w0=[0.92350205], w1=[1.], w3=[1.]\n",
      "GD iter. 20/499: loss=[[1.13636405]], w0=[0.13669419], w1=[1.], w3=[1.]\n",
      "GD iter. 40/499: loss=[[0.59984439]], w0=[0.02272274], w1=[1.], w3=[1.]\n",
      "GD iter. 60/499: loss=[[0.51866159]], w0=[0.00506661], w1=[1.], w3=[1.]\n",
      "GD iter. 80/499: loss=[[0.4978925]], w0=[0.00167864], w1=[1.], w3=[1.]\n",
      "GD iter. 100/499: loss=[[0.49070465]], w0=[0.0008718], w1=[1.], w3=[1.]\n",
      "GD iter. 120/499: loss=[[0.48749855]], w0=[0.00069102], w1=[1.], w3=[1.]\n",
      "GD iter. 140/499: loss=[[0.48576556]], w0=[0.00070431], w1=[1.], w3=[1.]\n",
      "GD iter. 160/499: loss=[[0.48470841]], w0=[0.00078138], w1=[1.], w3=[1.]\n",
      "GD iter. 180/499: loss=[[0.48401859]], w0=[0.00087453], w1=[1.], w3=[1.]\n",
      "GD iter. 200/499: loss=[[0.48355206]], w0=[0.00096535], w1=[1.], w3=[1.]\n",
      "GD iter. 220/499: loss=[[0.48323055]], w0=[0.00104722], w1=[1.], w3=[1.]\n",
      "GD iter. 240/499: loss=[[0.48300672]], w0=[0.00111845], w1=[1.], w3=[1.]\n",
      "GD iter. 260/499: loss=[[0.48285004]], w0=[0.00117934], w1=[1.], w3=[1.]\n",
      "GD iter. 280/499: loss=[[0.48274003]], w0=[0.00123091], w1=[1.], w3=[1.]\n",
      "GD iter. 300/499: loss=[[0.48266266]], w0=[0.00127437], w1=[1.], w3=[1.]\n",
      "GD iter. 320/499: loss=[[0.48260819]], w0=[0.00131091], w1=[1.], w3=[1.]\n",
      "GD iter. 340/499: loss=[[0.48256983]], w0=[0.00134159], w1=[1.], w3=[1.]\n",
      "GD iter. 360/499: loss=[[0.48254279]], w0=[0.00136733], w1=[1.], w3=[1.]\n",
      "GD iter. 380/499: loss=[[0.48252374]], w0=[0.00138892], w1=[1.], w3=[1.]\n",
      "GD iter. 400/499: loss=[[0.48251032]], w0=[0.00140703], w1=[1.], w3=[1.]\n",
      "GD iter. 420/499: loss=[[0.48250085]], w0=[0.00142222], w1=[1.], w3=[1.]\n",
      "GD iter. 440/499: loss=[[0.48249418]], w0=[0.00143497], w1=[1.], w3=[1.]\n",
      "GD iter. 460/499: loss=[[0.48248948]], w0=[0.00144566], w1=[1.], w3=[1.]\n",
      "GD iter. 480/499: loss=[[0.48248616]], w0=[0.00145464], w1=[1.], w3=[1.]\n"
     ]
    }
   ],
   "source": [
    "w_mse_gd,loss_gd = mean_squared_error_gd(y_train,new_datas,initial_w,max_iters,gamma)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T14:09:28.967711800Z",
     "start_time": "2023-10-23T14:07:59.789475600Z"
    }
   },
   "id": "d48479a82434b55d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
