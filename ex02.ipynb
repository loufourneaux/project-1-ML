{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=True, add_outlier=True)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((202,), (202, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2194109721.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    * there are **N = 10000** data entries\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "### NB: throughout this laboratory the data has the following format: \n",
    "  * there are **N = 10000** data entries\n",
    "  * **y** represents the column vector containing weight information -- that which we wish to predict/the output (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,)**.\n",
    "  * **tx** represents the matrix $\\tilde{X}$ formed by laterally concatenating a column vector of 1s to the column vector of height information -- the input data (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,2)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3700976558.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    Fill in the `compute_loss` function below:\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 1. Computing the Cost Function\n",
    "Fill in the `compute_loss` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_loss(y, tx, w):\n",
    "    \"\"\"Calculate the loss using Mean Squared Error (MSE).\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2,). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        loss_by_MSE: The value of the loss (a scalar) calculated using MSE.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the error (residuals) between actual y and predicted y using the given parameters w\n",
    "    e = y - np.dot(tx, w)\n",
    "    \n",
    "    # Calculate the Mean Squared Error (MSE)\n",
    "    #loss_by_MSE = np.mean(e**2) / 2.0  # Dividing by 2 is optional and simplifies the gradient computation\n",
    "    \n",
    "    # Calculate the Mean Absolute Error (MAE)\n",
    "    loss_by_MAE = np.mean(np.abs(e))\n",
    "    #return loss_by_MSE\n",
    "    return loss_by_MAE\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fill in the function `grid_search()` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from costs import *\n",
    "import numpy as np\n",
    "\n",
    "def grid_search(y, tx, grid_w0, grid_w1):\n",
    "    \"\"\"Algorithm for grid search.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        grid_w0: numpy array of shape=(num_grid_pts_w0, ). A 1D array containing num_grid_pts_w0 values of parameter w0 to be tested in the grid search.\n",
    "        grid_w1: numpy array of shape=(num_grid_pts_w1, ). A 1D array containing num_grid_pts_w1 values of parameter w1 to be tested in the grid search.\n",
    "\n",
    "    Returns:\n",
    "        losses: numpy array of shape=(num_grid_pts_w0, num_grid_pts_w1). A 2D array containing the loss value for each combination of w0 and w1\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the losses array\n",
    "    losses = np.zeros((len(grid_w0), len(grid_w1)))\n",
    "\n",
    "    # Iterate through each combination of w0 and w1\n",
    "    for i, w0 in enumerate(grid_w0):\n",
    "        for j, w1 in enumerate(grid_w1):\n",
    "            # Create the parameter vector w\n",
    "            w = np.array([w0, w1])\n",
    "            # Calculate the loss using the compute_loss function\n",
    "            loss = compute_loss(y, tx, w)\n",
    "            # Store the loss in the losses array\n",
    "            losses[i, j] = loss\n",
    "#We loop through each combination of `w0` and `w1` from the `grid_w0` and `grid_w1` arrays.\n",
    "# For each combination, we create a parameter vector `w` containing `w0` and `w1`.\n",
    "# We calculate the loss using the `compute_loss` function, passing in `y`, `tx`, and the `w` vector.\n",
    "# We store the computed loss in the `losses` array at the corresponding indices.\n",
    "# Finally, we return the `losses` array, which contains the loss values for each combination of `w0` and `w1`.\n",
    "\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Let us play with the grid search demo now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: loss*=5.464204730460844, w0*=71.42857142857142, w1*=15.306122448979579, execution time=0.119 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from grid_search import generate_w, get_best_parameters\n",
    "from plots import grid_visualization \n",
    "import datetime\n",
    "\n",
    "\n",
    "# Generate the grid of parameters to be swept\n",
    "grid_w0, grid_w1 = generate_w(num_intervals=50)\n",
    "\n",
    "# Start the grid search\n",
    "start_time = datetime.datetime.now()\n",
    "grid_losses = grid_search(y, tx, grid_w0, grid_w1)\n",
    "\n",
    "# Select the best combinaison\n",
    "loss_star, w0_star, w1_star = get_best_parameters(grid_w0, grid_w1, grid_losses)\n",
    "end_time = datetime.datetime.now()\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "# Print the results\n",
    "print(\n",
    "    \"Grid Search: loss*={l}, w0*={w0}, w1*={w1}, execution time={t:.3f} seconds\".format(\n",
    "        l=loss_star, w0=w0_star, w1=w1_star, t=execution_time\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "fig = grid_visualization(grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight)\n",
    "fig.set_size_inches(10.0, 6.0)\n",
    "fig.savefig(\"grid_plot\")  # Optional saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2337745732.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[15], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Again, please fill in the functions `compute_gradient` below:\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Again, please fill in the functions `compute_gradient` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for w0 = 100 and w1 = 20: [[-12.  -5.]\n",
      " [-36. -15.]]\n",
      "Gradient for w0 = 50 and w1 = 10: [[ 68.  75.]\n",
      " [214. 235.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Computes the gradient at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    # Calculate the error\n",
    "    e = y - np.dot(tx, w)\n",
    "    \n",
    "    # Calculate the gradient using the MSE formula\n",
    "    gradient_of_loss = -(1 / len(y)) * np.dot(tx.T, e)\n",
    "    \n",
    "    return gradient_of_loss\n",
    "\n",
    "# Define your data\n",
    "wline = [0, 0]\n",
    "y1 = np.array([12, 5])\n",
    "tx1 = np.array([[1, 2], [1, 4]])\n",
    "w = np.array(wline).reshape(-1, 1)\n",
    "\n",
    "# Compute the gradient for w0 = 100 and w1 = 20\n",
    "gradient_1 = compute_gradient(y1, tx1, w)\n",
    "\n",
    "# Define new data\n",
    "wline = [50, 10]\n",
    "w = np.array(wline).reshape(-1, 1)\n",
    "\n",
    "# Compute the gradient for w0 = 50 and w1 = 10\n",
    "gradient_2 = compute_gradient(y1, tx1, w)\n",
    "\n",
    "print(\"Gradient for w0 = 100 and w1 = 20:\", gradient_1)\n",
    "print(\"Gradient for w0 = 50 and w1 = 10:\", gradient_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Please fill in the functions `gradient_descent` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The Gradient Descent (GD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of GD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of GD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = []\n",
    "    losses=[]\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # Compute the gradient and loss\n",
    "        gradient = compute_gradient(y, tx, w)\n",
    "        loss = compute_loss(y, tx, w)\n",
    "\n",
    "        # Update w using the gradient and step size\n",
    "        w = w - gamma * gradient\n",
    "\n",
    "        # Store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "    \n",
    "        # Print progress (optional)\n",
    "        print(\n",
    "            \"GD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test your gradient descent function through gradient descent demo shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gradient_descent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Start gradient descent.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m start_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m---> 13\u001b[0m gd_losses, gd_ws \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_descent\u001b[49m(y, tx, w_initial, max_iters, gamma)\n\u001b[1;32m     14\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Print result\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gradient_descent' is not defined"
     ]
    }
   ],
   "source": [
    "# from gradient_descent import *\n",
    "from plots import gradient_descent_visualization\n",
    "import datetime\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([1, 1])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gd_ws' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 21\u001b[0m\n\u001b[1;32m      6\u001b[0m     fig \u001b[38;5;241m=\u001b[39m gradient_descent_visualization(\n\u001b[1;32m      7\u001b[0m         gd_losses,\n\u001b[1;32m      8\u001b[0m         gd_ws,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m         n_iter,\n\u001b[1;32m     17\u001b[0m     )\n\u001b[1;32m     18\u001b[0m     fig\u001b[38;5;241m.\u001b[39mset_size_inches(\u001b[38;5;241m10.0\u001b[39m, \u001b[38;5;241m6.0\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m interact(plot_figure, n_iter\u001b[38;5;241m=\u001b[39mIntSlider(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[43mgd_ws\u001b[49m)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gd_ws' is not defined"
     ]
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute a stochastic gradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the stochastic gradient of the loss at w.\n",
    "    \"\"\"\n",
    "\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    \n",
    "     # Calculate the error\n",
    "    e = y - np.dot(tx, w)\n",
    "    \n",
    "    # Calculate the gradient using the MSE formula\n",
    "    gradient_of_loss = -(1 / len(y)) * np.dot(tx.T, e)\n",
    "    \n",
    "    return gradient_of_loss\n",
    "    # TODO: implement stochastic gradient computation. It's the same as the usual gradient.\n",
    "    # ***************************************************\n",
    "\n",
    "\n",
    "\n",
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic Gradient Descent algorithm (SGD).\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic gradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        for minibatch_y, minibatch_tx in batch_iter(y, tx, batch_size):\n",
    "            # Calculate the stochastic gradient for the current mini-batch\n",
    "            gradient = compute_stoch_gradient(minibatch_y, minibatch_tx, w)\n",
    "            # Update the model parameters\n",
    "            w = w- gamma * gradient #-= means w= w -gamma*gradient\n",
    "            # Calculate and store the loss using compute_loss\n",
    "            loss = compute_loss(y, tx, w)\n",
    "            losses.append(loss)\n",
    "            ws.append(w)\n",
    "      \n",
    "        # TODO: implement stochastic gradient descent.\n",
    "        # ***************************************************\n",
    "        \n",
    "\n",
    "        print(\n",
    "            \"SGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/49: loss=67.39244221332439, w0=6.675363641601992, w1=-1.9573257493229805\n",
      "SGD iter. 1/49: loss=60.33946200206094, w0=13.728343852865434, w1=0.8064652140703901\n",
      "SGD iter. 2/49: loss=54.16941841232441, w0=19.89838744260197, w1=2.3543046070264175\n",
      "SGD iter. 3/49: loss=49.44043690828646, w0=24.62736894663992, w1=2.69059863350776\n",
      "SGD iter. 4/49: loss=44.670361976322, w0=29.39744387860437, w1=4.551242202970572\n",
      "SGD iter. 5/49: loss=39.879532922536534, w0=34.188272932389836, w1=7.521248764155291\n",
      "SGD iter. 6/49: loss=35.99796035825474, w0=38.06984549667163, w1=7.651075793533608\n",
      "SGD iter. 7/49: loss=33.02359329175888, w0=41.04421256316749, w1=7.249339264789991\n",
      "SGD iter. 8/49: loss=29.236384484640727, w0=44.83142137028564, w1=9.90483618565868\n",
      "SGD iter. 9/49: loss=26.15445922300619, w0=47.91334663192018, w1=11.190722084993055\n",
      "SGD iter. 10/49: loss=23.870276808608782, w0=50.197529046317584, w1=11.60488296114633\n",
      "SGD iter. 11/49: loss=21.544488127752214, w0=52.52331772717415, w1=12.766495290423924\n",
      "SGD iter. 12/49: loss=19.35545616523094, w0=54.71234968969542, w1=13.27103695261155\n",
      "SGD iter. 13/49: loss=17.442067881574154, w0=56.62573797335221, w1=13.888842892844341\n",
      "SGD iter. 14/49: loss=16.183876322492168, w0=57.883929532434195, w1=13.920076520281803\n",
      "SGD iter. 15/49: loss=14.19475662027883, w0=59.876586761713796, w1=14.588975025079346\n",
      "SGD iter. 16/49: loss=12.86247756960429, w0=61.23492315260553, w1=15.03355656963529\n",
      "SGD iter. 17/49: loss=11.68226158742019, w0=62.450830304669644, w1=15.014688933308445\n",
      "SGD iter. 18/49: loss=10.647853164294995, w0=63.53129308594945, w1=14.767619519295543\n",
      "SGD iter. 19/49: loss=9.544415383566324, w0=64.73198287635242, w1=15.210045154999202\n",
      "SGD iter. 20/49: loss=8.722718236582322, w0=65.68809077654022, w1=15.082805583229264\n",
      "SGD iter. 21/49: loss=7.823511983371208, w0=66.78657537961324, w1=15.032007280017725\n",
      "SGD iter. 22/49: loss=7.163631891283958, w0=67.72354873377147, w1=15.093022069357417\n",
      "SGD iter. 23/49: loss=6.851705281931569, w0=68.20590783387831, w1=15.301376835244744\n",
      "SGD iter. 24/49: loss=8.361037452740012, w0=69.6999067891847, w1=8.890913813288869\n",
      "SGD iter. 25/49: loss=8.213836830927425, w0=69.54492103402528, w1=9.257634508915908\n",
      "SGD iter. 26/49: loss=7.651435898585996, w0=70.13695532925946, w1=10.072658213200647\n",
      "SGD iter. 27/49: loss=6.896743951784262, w0=70.95715189342947, w1=11.198857662124462\n",
      "SGD iter. 28/49: loss=6.678306984986931, w0=71.2740972000734, w1=11.511097860214493\n",
      "SGD iter. 29/49: loss=6.54138790792992, w0=71.63234462772378, w1=11.658697634971269\n",
      "SGD iter. 30/49: loss=11.9530490323888, w0=73.64578676813042, w1=2.3055070741833106\n",
      "SGD iter. 31/49: loss=11.184145535335375, w0=73.10459170380985, w1=3.4349922339378063\n",
      "SGD iter. 32/49: loss=10.507790781020464, w0=73.12101010190291, w1=4.46770258181246\n",
      "SGD iter. 33/49: loss=10.101820455771618, w0=72.92248085564127, w1=5.104938005040489\n",
      "SGD iter. 34/49: loss=9.294885695815795, w0=73.38141554273435, w1=6.349038258362927\n",
      "SGD iter. 35/49: loss=8.878026238544166, w0=74.05476533929284, w1=7.020458687092836\n",
      "SGD iter. 36/49: loss=8.450003515294082, w0=73.61631084477439, w1=7.701916403062522\n",
      "SGD iter. 37/49: loss=8.14543995870258, w0=73.71058502278235, w1=8.202171454046127\n",
      "SGD iter. 38/49: loss=7.879795229695766, w0=73.19263347452772, w1=8.69045747573805\n",
      "SGD iter. 39/49: loss=7.543093594644474, w0=73.23874859320182, w1=9.28701623253338\n",
      "SGD iter. 40/49: loss=7.364429152096418, w0=73.59147216100268, w1=9.607618227394074\n",
      "SGD iter. 41/49: loss=9.989680632918503, w0=74.86333853734214, w1=5.3531796901708555\n",
      "SGD iter. 42/49: loss=9.508304957989628, w0=74.35964016516716, w1=6.0485193014782945\n",
      "SGD iter. 43/49: loss=9.029467313104945, w0=74.55844632193296, w1=6.8262384714407\n",
      "SGD iter. 44/49: loss=8.658210571712502, w0=74.4795659325018, w1=7.408278532415142\n",
      "SGD iter. 45/49: loss=8.304652048630905, w0=74.59669714443822, w1=8.006881725980737\n",
      "SGD iter. 46/49: loss=7.864796935146842, w0=74.69896421652442, w1=8.79451958980793\n",
      "SGD iter. 47/49: loss=7.532805347866108, w0=74.82960752216836, w1=9.41397074999566\n",
      "SGD iter. 48/49: loss=7.125386473248855, w0=74.94296084431078, w1=10.196217970311695\n",
      "SGD iter. 49/49: loss=6.833195860066836, w0=74.85968664839478, w1=10.75880015415211\n",
      "SGD: execution time=0.008 seconds\n"
     ]
    }
   ],
   "source": [
    "# from stochastic_gradient_descent import *\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "batch_size = 9\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SGD.\n",
    "start_time = datetime.datetime.now()\n",
    "sgd_losses, sgd_ws = stochastic_gradient_descent(y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc134554523e46b79109e1ac22087fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        sgd_losses,\n",
    "        sgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(sgd_ws)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Effect of Outliers and MAE Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: reload the data by subsampling first, then by subsampling and adding outliers\n",
    "# ***************************************************\n",
    "\n",
    "\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 18\u001b[0m\n\u001b[1;32m     11\u001b[0m start_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# ***************************************************\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# INSERT YOUR CODE HERE\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# TODO: fit the model to the subsampled data / subsampled data with outliers and visualize the cloud of points\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#       and the model fit\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# ***************************************************\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[1;32m     21\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Print result\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: fit the model to the subsampled data / subsampled data with outliers and visualize the cloud of points\n",
    "#       and the model fit\n",
    "# ***************************************************\n",
    "\n",
    "\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Subgradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_subgradient_mae(y, tx, w):\n",
    "    \"\"\"Compute a subgradient of the MAE at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        subgradient: A numpy array of shape (2, ) containing the subgradient of the MAE at w.\n",
    "    \"\"\"\n",
    "    \n",
    "    N = len(y)  # Number of data points\n",
    "    \n",
    "    # Calculate the error (residuals) between actual y and predicted y using the given parameters w\n",
    "    e = y - np.dot(tx, w)\n",
    "    \n",
    "    # Compute the subgradient\n",
    "    subgradient = np.zeros(w.shape)  # Initialize the subgradient vector\n",
    "    \n",
    "    for i in range(len(w)):\n",
    "        subgradient[i] = (1 / N) * np.dot(-tx[:, i], np.sign(e))\n",
    "    \n",
    "    return subgradient\n",
    "\n",
    "    # TODO: compute subgradient gradient vector for MAE\n",
    "    # ***************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The SubGradient Descent (SubGD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubGD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        # Compute loss and subgradient\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        subgradient = compute_subgradient_mae(y, tx, w)\n",
    "        \n",
    "        # Update w by subgradient\n",
    "        w = w- gamma * subgradient\n",
    "        \n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"SubGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws\n",
    "\n",
    "        # TODO: update w by subgradient\n",
    "        # ***************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubGD iter. 0/19: loss=74.06780585492638, w0=0.7, w1=7.771561172376096e-16\n",
      "SubGD iter. 1/19: loss=73.36780585492637, w0=1.4, w1=1.5543122344752192e-15\n",
      "SubGD iter. 2/19: loss=72.66780585492637, w0=2.0999999999999996, w1=2.3314683517128287e-15\n",
      "SubGD iter. 3/19: loss=71.96780585492637, w0=2.8, w1=3.1086244689504383e-15\n",
      "SubGD iter. 4/19: loss=71.26780585492638, w0=3.5, w1=3.885780586188048e-15\n",
      "SubGD iter. 5/19: loss=70.56780585492638, w0=4.2, w1=4.6629367034256575e-15\n",
      "SubGD iter. 6/19: loss=69.86780585492637, w0=4.9, w1=5.440092820663267e-15\n",
      "SubGD iter. 7/19: loss=69.16780585492639, w0=5.6000000000000005, w1=6.217248937900877e-15\n",
      "SubGD iter. 8/19: loss=68.46780585492637, w0=6.300000000000001, w1=6.994405055138486e-15\n",
      "SubGD iter. 9/19: loss=67.76780585492638, w0=7.000000000000001, w1=7.771561172376096e-15\n",
      "SubGD iter. 10/19: loss=67.06780585492638, w0=7.700000000000001, w1=8.548717289613705e-15\n",
      "SubGD iter. 11/19: loss=66.36780585492637, w0=8.4, w1=9.325873406851315e-15\n",
      "SubGD iter. 12/19: loss=65.66780585492639, w0=9.1, w1=1.0103029524088925e-14\n",
      "SubGD iter. 13/19: loss=64.96780585492637, w0=9.799999999999999, w1=1.0880185641326534e-14\n",
      "SubGD iter. 14/19: loss=64.26780585492638, w0=10.499999999999998, w1=1.1657341758564144e-14\n",
      "SubGD iter. 15/19: loss=63.567805854926384, w0=11.199999999999998, w1=1.2434497875801753e-14\n",
      "SubGD iter. 16/19: loss=62.867805854926374, w0=11.899999999999997, w1=1.3211653993039363e-14\n",
      "SubGD iter. 17/19: loss=62.167805854926385, w0=12.599999999999996, w1=1.3988810110276972e-14\n",
      "SubGD iter. 18/19: loss=61.46780585492638, w0=13.299999999999995, w1=1.4765966227514582e-14\n",
      "SubGD iter. 19/19: loss=60.76780585492638, w0=13.999999999999995, w1=1.554312234475219e-14\n",
      "SubGD: execution time=0.004 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 20\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subgd_losses, subgd_ws = subgradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "444b608e910b4504a5da1f0bfd3a16de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=21, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "from plots import gradient_descent_visualization\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig =gradient_descent_visualization(\n",
    "        subgd_losses,\n",
    "        subgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subgd_ws)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Subgradient Descent\n",
    "\n",
    "**NB** for the computation of the subgradient you can reuse the `compute_subgradient` method that you implemented above, just making sure that you pass in a minibatch as opposed to the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_subgradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"Compute a stochastic subgradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B, 2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic subgradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SubSGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubSGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubSGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        for minibatch_y, minibatch_tx in batch_iter(y, tx, batch_size):\n",
    "            # Compute loss and subgradient for the current mini-batch\n",
    "            minibatch_loss = compute_loss(minibatch_y, minibatch_tx, w)\n",
    "            minibatch_subgradient = compute_subgradient_mae(minibatch_y, minibatch_tx, w)\n",
    "            # Update the model parameters\n",
    "            w = w - gamma * minibatch_subgradient\n",
    "            # Calculate and store the loss using compute_loss\n",
    "            losses.append(minibatch_loss)\n",
    "            ws.append(w)\n",
    "            print(\n",
    "                \"SubSGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                    bi=n_iter, ti=max_iters - 1, l=minibatch_loss, w0=w[0], w1=w[1]\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return losses, ws\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubSGD iter. 0/99: loss=75.1876782867415, w0=0.7, w1=-0.24097991466664814\n",
      "SubSGD iter. 1/99: loss=47.224644302326354, w0=1.4, w1=-1.5949368086998756\n",
      "SubSGD iter. 2/99: loss=104.35047904455898, w0=2.0999999999999996, w1=-4.968080486289553\n",
      "SubSGD iter. 3/99: loss=92.69173157798818, w0=2.8, w1=-4.353419505159167\n",
      "SubSGD iter. 4/99: loss=58.299910966080915, w0=3.5, w1=-4.723687595687963\n",
      "SubSGD iter. 5/99: loss=85.20272588007379, w0=4.2, w1=-4.21450175174171\n",
      "SubSGD iter. 6/99: loss=84.02772152397833, w0=4.9, w1=-3.5833364117468576\n",
      "SubSGD iter. 7/99: loss=65.8517412436227, w0=5.6000000000000005, w1=-3.982794184133436\n",
      "SubSGD iter. 8/99: loss=95.70511613174972, w0=6.300000000000001, w1=-3.1035462182372644\n",
      "SubSGD iter. 9/99: loss=58.47194520181801, w0=7.000000000000001, w1=-3.1288439836261057\n",
      "SubSGD iter. 10/99: loss=91.00484484349234, w0=7.700000000000001, w1=-1.960513183108637\n",
      "SubSGD iter. 11/99: loss=43.34915291296015, w0=8.4, w1=-2.937310662050556\n",
      "SubSGD iter. 12/99: loss=85.67241274739152, w0=9.1, w1=-2.29438096328676\n",
      "SubSGD iter. 13/99: loss=37.12555932300404, w0=9.799999999999999, w1=-2.9749801409428427\n",
      "SubSGD iter. 14/99: loss=50.4644324426382, w0=10.499999999999998, w1=-3.4059908256914566\n",
      "SubSGD iter. 15/99: loss=46.936003339441, w0=11.199999999999998, w1=-4.084337821666\n",
      "SubSGD iter. 16/99: loss=40.84581379487808, w0=11.899999999999997, w1=-4.6971359926674126\n",
      "SubSGD iter. 17/99: loss=95.02087433116588, w0=12.599999999999996, w1=-3.5788257720559313\n",
      "SubSGD iter. 18/99: loss=56.408655930951575, w0=13.299999999999995, w1=-3.9748020152777634\n",
      "SubSGD iter. 19/99: loss=86.11678602109772, w0=13.999999999999995, w1=-2.806471214760295\n",
      "SubSGD iter. 20/99: loss=27.833961730632762, w0=14.699999999999994, w1=-3.932403628261466\n",
      "SubSGD iter. 21/99: loss=72.70525306284894, w0=15.399999999999993, w1=-3.721239233695262\n",
      "SubSGD iter. 22/99: loss=81.63668685548275, w0=16.099999999999994, w1=-2.926069508577915\n",
      "SubSGD iter. 23/99: loss=89.82016610829368, w0=16.799999999999994, w1=-1.5633181131861682\n",
      "SubSGD iter. 24/99: loss=48.44902767691259, w0=17.499999999999993, w1=-1.9292388439165655\n",
      "SubSGD iter. 25/99: loss=60.23277940736343, w0=18.199999999999992, w1=-1.323835692472581\n",
      "SubSGD iter. 26/99: loss=29.518079935592898, w0=18.89999999999999, w1=-2.535258580398761\n",
      "SubSGD iter. 27/99: loss=60.19507987015837, w0=19.59999999999999, w1=-2.2467613158413453\n",
      "SubSGD iter. 28/99: loss=34.092909343919814, w0=20.29999999999999, w1=-3.284275509654886\n",
      "SubSGD iter. 29/99: loss=72.9959784977221, w0=20.99999999999999, w1=-2.6322186122124305\n",
      "SubSGD iter. 30/99: loss=56.86274211401967, w0=21.69999999999999, w1=-2.3819374957503743\n",
      "SubSGD iter. 31/99: loss=66.1211922152969, w0=22.399999999999988, w1=-1.7628040998057077\n",
      "SubSGD iter. 32/99: loss=90.3008579962599, w0=23.099999999999987, w1=-0.22274176141852187\n",
      "SubSGD iter. 33/99: loss=68.24773825475154, w0=23.799999999999986, w1=0.3304641546575915\n",
      "SubSGD iter. 34/99: loss=83.95308265900657, w0=24.499999999999986, w1=1.5112688553574873\n",
      "SubSGD iter. 35/99: loss=36.58348870181665, w0=25.199999999999985, w1=1.2940118511777372\n",
      "SubSGD iter. 36/99: loss=50.433150951705, w0=25.899999999999984, w1=1.053031936511089\n",
      "SubSGD iter. 37/99: loss=52.45326622569515, w0=26.599999999999984, w1=1.1963625271056053\n",
      "SubSGD iter. 38/99: loss=32.58217809995944, w0=27.299999999999983, w1=0.8110783867774773\n",
      "SubSGD iter. 39/99: loss=44.10134405597513, w0=27.999999999999982, w1=0.8175062676558238\n",
      "SubSGD iter. 40/99: loss=61.47512835529466, w0=28.69999999999998, w1=1.469563165098279\n",
      "SubSGD iter. 41/99: loss=28.24384555524765, w0=29.39999999999998, w1=0.9175917331605999\n",
      "SubSGD iter. 42/99: loss=60.22359863367521, w0=30.09999999999998, w1=1.5322527142909865\n",
      "SubSGD iter. 43/99: loss=58.04260257879595, w0=30.79999999999998, w1=2.411982844123465\n",
      "SubSGD iter. 44/99: loss=51.87266868717697, w0=31.49999999999998, w1=2.5258031709377775\n",
      "SubSGD iter. 45/99: loss=35.88659088881526, w0=32.19999999999998, w1=2.1598824402073804\n",
      "SubSGD iter. 46/99: loss=58.786601610528166, w0=32.899999999999984, w1=2.8918470337150155\n",
      "SubSGD iter. 47/99: loss=45.46456278194823, w0=33.59999999999999, w1=3.387473294183848\n",
      "SubSGD iter. 48/99: loss=25.967349666406683, w0=34.29999999999999, w1=2.5876425601211386\n",
      "SubSGD iter. 49/99: loss=50.42747340552722, w0=34.99999999999999, w1=2.7839871536383667\n",
      "SubSGD iter. 50/99: loss=27.41267926605581, w0=35.699999999999996, w1=2.5014393345521415\n",
      "SubSGD iter. 51/99: loss=30.88076192804492, w0=36.4, w1=2.30068979750289\n",
      "SubSGD iter. 52/99: loss=46.08640976383968, w0=37.1, w1=3.0016237949376428\n",
      "SubSGD iter. 53/99: loss=46.963365728821024, w0=37.800000000000004, w1=3.4291408801550607\n",
      "SubSGD iter. 54/99: loss=22.153209457032183, w0=38.50000000000001, w1=2.9889456254480895\n",
      "SubSGD iter. 55/99: loss=56.14169771689073, w0=39.20000000000001, w1=4.107255846059571\n",
      "SubSGD iter. 56/99: loss=29.013285629523956, w0=39.90000000000001, w1=3.741335115329174\n",
      "SubSGD iter. 57/99: loss=34.64804173471636, w0=40.600000000000016, w1=3.8516351487899656\n",
      "SubSGD iter. 58/99: loss=49.77799321934468, w0=41.30000000000002, w1=4.4646276459735255\n",
      "SubSGD iter. 59/99: loss=27.06055027007085, w0=42.00000000000002, w1=3.910520571976945\n",
      "SubSGD iter. 60/99: loss=32.39513729133454, w0=42.700000000000024, w1=3.886554732173854\n",
      "SubSGD iter. 61/99: loss=17.50837652667068, w0=43.40000000000003, w1=3.316594607637868\n",
      "SubSGD iter. 62/99: loss=13.271140611281481, w0=44.10000000000003, w1=2.41496234322511\n",
      "SubSGD iter. 63/99: loss=46.619873814064775, w0=44.80000000000003, w1=3.1469269367327453\n",
      "SubSGD iter. 64/99: loss=16.320954208960885, w0=45.500000000000036, w1=2.723687511960231\n",
      "SubSGD iter. 65/99: loss=27.04543710553485, w0=46.20000000000004, w1=2.596673066732206\n",
      "SubSGD iter. 66/99: loss=35.2449669636532, w0=46.90000000000004, w1=3.554808157634013\n",
      "SubSGD iter. 67/99: loss=17.281484882185943, w0=47.600000000000044, w1=2.8764611616594697\n",
      "SubSGD iter. 68/99: loss=15.32642302531287, w0=48.30000000000005, w1=2.4506750143687306\n",
      "SubSGD iter. 69/99: loss=28.65001740008922, w0=49.00000000000005, w1=2.4659826810808667\n",
      "SubSGD iter. 70/99: loss=8.845206817115319, w0=49.70000000000005, w1=1.6817499530415425\n",
      "SubSGD iter. 71/99: loss=29.521356911803082, w0=50.400000000000055, w1=2.177376213510375\n",
      "SubSGD iter. 72/99: loss=19.061835680652685, w0=51.10000000000006, w1=2.4380884348922387\n",
      "SubSGD iter. 73/99: loss=11.559775833302062, w0=51.80000000000006, w1=2.0123022876014995\n",
      "SubSGD iter. 74/99: loss=22.58333146589034, w0=52.500000000000064, w1=2.5606967913593106\n",
      "SubSGD iter. 75/99: loss=8.909196658214135, w0=53.20000000000007, w1=2.3434397871795603\n",
      "SubSGD iter. 76/99: loss=35.67136244548636, w0=53.90000000000007, w1=3.511770587697029\n",
      "SubSGD iter. 77/99: loss=21.39307462546472, w0=54.60000000000007, w1=3.8469986430002843\n",
      "SubSGD iter. 78/99: loss=33.51642765435396, w0=55.300000000000075, w1=4.930874039691586\n",
      "SubSGD iter. 79/99: loss=25.89250499554982, w0=56.00000000000008, w1=5.460575013753703\n",
      "SubSGD iter. 80/99: loss=83.74941489608534, w0=56.70000000000008, w1=2.0874313361640255\n",
      "SubSGD iter. 81/99: loss=14.165194667893964, w0=57.400000000000084, w1=1.7510683784879488\n",
      "SubSGD iter. 82/99: loss=12.71956414781647, w0=58.10000000000009, w1=1.2264354537762094\n",
      "SubSGD iter. 83/99: loss=1.8597717653507786, w0=58.80000000000009, w1=0.8031960290036952\n",
      "SubSGD iter. 84/99: loss=7.032384248621966, w0=58.10000000000009, w1=1.6446145387296398\n",
      "SubSGD iter. 85/99: loss=16.217559661332103, w0=58.80000000000009, w1=1.620648698926549\n",
      "SubSGD iter. 86/99: loss=23.475370693531247, w0=59.50000000000009, w1=2.212966660194727\n",
      "SubSGD iter. 87/99: loss=29.922812099504483, w0=60.200000000000095, w1=2.7661725762708405\n",
      "SubSGD iter. 88/99: loss=31.20345006529014, w0=60.9000000000001, w1=3.6223946287753783\n",
      "SubSGD iter. 89/99: loss=20.26146814038752, w0=61.6000000000001, w1=4.253559968770231\n",
      "SubSGD iter. 90/99: loss=14.766391167552335, w0=62.300000000000104, w1=4.342087482259357\n",
      "SubSGD iter. 91/99: loss=9.648598681955612, w0=63.00000000000011, w1=4.005724524583281\n",
      "SubSGD iter. 92/99: loss=2.3088236828364472, w0=63.70000000000011, w1=3.6553875912148897\n",
      "SubSGD iter. 93/99: loss=2.0969965959810537, w0=64.4000000000001, w1=3.5348830397358473\n",
      "SubSGD iter. 94/99: loss=19.134356596256794, w0=65.10000000000011, w1=4.14879745311343\n",
      "SubSGD iter. 95/99: loss=4.623519519287306, w0=64.4000000000001, w1=4.559872637655657\n",
      "SubSGD iter. 96/99: loss=9.080084855207474, w0=65.10000000000011, w1=4.612032983185367\n",
      "SubSGD iter. 97/99: loss=8.376198138570643, w0=65.80000000000011, w1=4.664193328715077\n",
      "SubSGD iter. 98/99: loss=7.426685199553731, w0=65.10000000000011, w1=5.2113556309489475\n",
      "SubSGD iter. 99/99: loss=10.802398427936225, w0=65.80000000000011, w1=5.499852895506363\n",
      "SubSGD: execution time=0.018 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 100\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subsgd_losses, subsgd_ws = stochastic_subgradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubSGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c454b1eabffa4f6ba7318ab95d9d9d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=101, min=1), Output()), _dom_classes=('widg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subsgd_losses,\n",
    "        subsgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subsgd_ws)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
