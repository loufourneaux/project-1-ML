# CS-433: Machine Learning Fall 2023, Project 1 
- Team Name: Clementines
- Team Member:
    1. Lou, **SCIPER: 311084** (lou.fourneaux@epfl.ch)
    2. Adrien Feillard, **SCIPER: 315921** (adrien.feillard@epfl.ch)
    3. Laissy Aurélien, **SCIPER: 329573** (aurelien.laissy@epfl.ch)

* [Getting started](#getting-started)
    * [Project description](#project-description)
    * [Data](#data)
    * [Report](#report)
* [Reproduce results](#reproduce-results)
    * [Requirements](#Requirements)
    * [Repo Architecture](#repo-architecture)
    * [Instructions to run](#instructions-to-run)
* [Results](#results)

# Getting started
## Project description
The aim of this project of Machine Learning do some early detection and prevention MICHD diseases.Our job is to estimate the likelihood of developing MICHD given a certain clinical and lifestyle situation.
The model is based on a vector of features collecting the health-related data of a person.

More detail about the project ara available in `references/project1_description.pdf`. Here a regularized logistic regression is implemented and trained on 8 sub-sets of the full dataset. 
## Data
The data that you will use comes from the Behavioral Risk Factor Surveillance System (BRFSS), a system of
health-related telephone surveys that collects state data about U.S. residents regarding their health-related risk
behaviors, chronic health conditions, and use of preventive services. In particular, respondents were classified
as having coronary heart disease (MICHD) if they reported having been told by a provider they had MICHD.
Respondents were also classified as having MICHD if they reported having been told they had a heart attack (i.e.,
myocardial infarction) or angina.
 The dataset is available at https://www.aicrowd.com/challenges/epfl-machine-learning-project-1/dataset_files. To reproduce the results a folder `data/` should be added to the repo, as described in [Repo Architecture](#repo-architecture). A detailed description of the dataset is available in 'https://www.cdc.gov/brfss/annual_data/annual_2015.html'
.

## Report
All the details about the choices that have been made and the methodology used throughout this project are available in `report.pdf`. Through this report, the reader is able to understand the different assumptions, decisions and results made during the project
# Reproduce results
## Requirements
- Python==3.9.13
- Numpy==1.21.5
- Matplotlib

## Repo Architecture
<pre>  
├─── data
    ├─── submission.csv: File generated by run.py. Contains predictions of sample from test.csv. 
    ├─── test.csv: File containing samples to be predicted.
    ├─── train.csv: File with labeled sample using for training.
├─── notebooks
    ├─── data_analysis.ipynb: Exploratory data analysis notebooks. Helps to visualize distributions of features.
    ├─── experiments.ipynb: Notebooks assessing performance of very basics models.
├─── references
    ├─── project1_description.pdf: Original description of the project provided by EPFL.
    ├─── 2015_Codebook_Report.pdf: Reference used to understand features of the dataset.
├─── src
    ├─── __init__.py: File to define src directory as a python package
    ├─── best_params.pkl: File generated by optimization.py. Contains best degree and lambda_ for each sub-models. This file is loaded in run.py.
    ├─── data_processing.py: File containing implementations to process the raw data.
    ├─── helpers.py: File provided by EPFL containing methods to load the data and create submissions for aircrowd.
    ├─── model.py: File containing definition of subfonctions used in implementations.py
    ├─── cross_validation.py: File containing functions to find the best hyperparameters for each optimization methods
├─── implementations.py: File containing basics ML implementations asked in the project description.
├─── README.md: README
├─── report.pdf: Report explaining choices that has been made.
└─── run.py: File that load the dataset, launch the cross validation, trains models with parameters  and generate submissison.csv.

## Instructions to run 
Move to the root folder and execute:

    python run.py

Make sure to have all the requirements and the data folder in the root. 

# Results
The performances of the models is assessed on AirCrowd from `data/submission.csv` generated by `run.py`. The model achieves a global accuracy of "enter our best accuracy" with a F1-score of "best f1 score".
