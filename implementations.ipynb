{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2baca1b-11c2-48fe-ab6f-4c6b1271aae4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e13ee9a6-ad45-466b-b1b5-2c051b032cc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from costs import *\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f05a2e2-a04d-47c6-bf9e-232114648800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Linear regression using gradient descent\n",
    "def mean_squared_error_gd(y, tx, initial_w, max_iters, gamma):\n",
    "    \n",
    "    #gradient descent\n",
    "    losses, ws = gradient_descent(y, tx, initial_w, max_iters, gamma)\n",
    "    \n",
    "    #find the best w \n",
    "    if gamma <= 2 :\n",
    "        loss = losses[max_iters-1]\n",
    "        w = ws[max_iters-1]\n",
    "    else :\n",
    "        loss = np.min(losses)\n",
    "        w = ws[np.argmin(losses)]\n",
    "    \n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69575d21-f5c3-43a3-b4c6-a52fbd7bd234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#linear regression using stochastic gradient descent \n",
    "def mean_squared_error_sgd(y, tx, initial_w, max_iters, gamma):\n",
    "    #gradient descent\n",
    "    losses, ws = stochastic_gradient_descent(y, tx, initial_w, max_iters, gamma)\n",
    "    \n",
    "    #find the best w \n",
    "    if gamma <= 2 :\n",
    "        loss = losses[max_iters-1]\n",
    "        w = ws[max_iters-1]\n",
    "    else :\n",
    "        loss = np.min(losses)\n",
    "        w = ws[np.argmin(losses)]\n",
    "    \n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbfd186a-dc6e-472b-8d1a-22d559e07e7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def least_squares(y, tx):\n",
    "    \"\"\"Calculate the least squares solution.\n",
    "       returns mse, and optimal weights.\n",
    "    \n",
    "    Args:\n",
    "        y: numpy array of shape (N,), N is the number of samples.\n",
    "        tx: numpy array of shape (N,D), D is the number of features.\n",
    "    \n",
    "    Returns:\n",
    "        w: optimal weights, numpy array of shape(D,), D is the number of features.\n",
    "        mse: scalar.    \"\"\"\n",
    "    \n",
    "    a = np.dot(tx.T,tx)\n",
    "    b = np.dot(tx.T,y)\n",
    "    w = np.linalg.solve(a, b)\n",
    "    \n",
    "    loss = compute_mse(y, tx, w)\n",
    "    \n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "831568e6-9e12-4d64-b7d0-7af3d435cff3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    \"\"\"implement ridge regression.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape (N,), N is the number of samples.\n",
    "        tx: numpy array of shape (N,D), D is the number of features.\n",
    "        lambda_: scalar.\n",
    "\n",
    "    Returns:\n",
    "        w: optimal weights, numpy array of shape(D,), D is the number of features.\n",
    "\n",
    "    >>> ridge_regression(np.array([0.1,0.2]), np.array([[2.3, 3.2], [1., 0.1]]), 0)\n",
    "    array([ 0.21212121, -0.12121212])\n",
    "    >>> ridge_regression(np.array([0.1,0.2]), np.array([[2.3, 3.2], [1., 0.1]]), 1)\n",
    "    array([0.03947092, 0.00319628])\n",
    "    \"\"\"\n",
    "    # Calculate the dimensions\n",
    "    N, D = tx.shape\n",
    "\n",
    "    # Compute the optimal weights using the closed-form solution for ridge regression\n",
    "    A = np.dot(tx.T, tx) + 2 * N * lambda_ * np.identity(D)\n",
    "    b = np.dot(tx.T, y)\n",
    "    w = np.linalg.solve(A, b)\n",
    "    loss = compute_mse(y, tx, w)\n",
    "\n",
    "    return w, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a47416bd-585c-4308-bbb7-c019ff3a9b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(y, tx, initial_w, max_iters, gamma):\n",
    "\n",
    "    w = initial_w\n",
    "    assert y.shape[0] == tx.shape[0]\n",
    "    assert tx.shape[1] == w.shape[0]\n",
    "\n",
    "    for iter in range(max_iters):\n",
    "\n",
    "        # LOSS\n",
    "        loss = calculate_loss(y, tx, w)\n",
    "\n",
    "        # GRADIENT\n",
    "        grad = calculate_gradient(y, tx, w)\n",
    "\n",
    "        # UPDATE W\n",
    "        w -= gamma * grad\n",
    "\n",
    "    return w, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ad90133-7dd3-4b91-b6cf-e3f18ea5976b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reg_logistic_regression(y, tx, lambda_, initial_w, max_iters, gamma):\n",
    "    \"\"\"\n",
    "    Do the gradient descent using the penalized logistic regression.\n",
    "    Return loss and w.\n",
    "\n",
    "    Args:\n",
    "        y:  shape=(N, 1)\n",
    "        tx: shape=(N, D)\n",
    "        w:  shape=(D, 1)\n",
    "        gamma: scalar\n",
    "        lambda_: scalar\n",
    "\n",
    "    Returns:\n",
    "        loss: scalar number\n",
    "        w: shape=(D, 1)\n",
    "    \"\"\"\n",
    "\n",
    "    w = initial_w\n",
    "    for iter in range(max_iters):\n",
    "\n",
    "\n",
    "        # LOSS PENALIZED\n",
    "        loss = calculate_loss(y, tx, w)\n",
    "        loss += lambda_ * np.linalg.norm(w) ** 2\n",
    "\n",
    "        # GRADIENT PENALIZED\n",
    "        grad = calculate_gradient(y, tx, w)\n",
    "        grad += 2 * lambda_ * w\n",
    "\n",
    "        # NEW STEP OF W\n",
    "        w -= gamma * grad\n",
    "\n",
    "    return w, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13884bf2-0bdc-4fbf-9706-3c839f5a658e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
